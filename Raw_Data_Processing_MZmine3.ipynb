{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4aca50c0",
   "metadata": {},
   "source": [
    "## Data Processing - FBMN\n",
    "Authors: Abzer Kelminal (abzer.shah@uni-tuebingen.de) <br>\n",
    "Edited by:  <br>\n",
    "Input file format: .csv files or .txt files <br>\n",
    "Outputs: .csv files  <br>\n",
    "Dependencies: ggplot2, readxl, dplyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f82436",
   "metadata": {},
   "outputs": [],
   "source": [
    "setwd("")\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add9f6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install packages if not present\n",
    "install.packages('readxl')\n",
    "install.packages('dplyr')\n",
    "install.packages('ggplot2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b336b375",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(readxl)\n",
    "library(dplyr)\n",
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f257de7",
   "metadata": {},
   "source": [
    "### Creating a function - FrequencyPlot:\n",
    "The below function takes in the two input data tables, calculates the frequency distribution of the data in the order of 10 and produces a grouped barplot showing the distribution as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bac8e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=5, repr.plot.height=3) #'global' settings for plot size in the output cell\n",
    "\n",
    "FrequencyPlot <- function(x1,x2){\n",
    "  \n",
    "  bins <- c(-1,0,(1 * 10^(seq(0,10,1)))) #creating bins from -1 to 10^10 using sequence function: seq()\n",
    "  \n",
    "  scores_x1 <- cut(as.matrix(x1),bins,labels = c('0','1','10','1E2','1E3','1E4','1E5','1E6','1E7','1E8','1E9','1E10')) #cut function store the data into the appropriate bins\n",
    "  Table_x1<-transform(table(scores_x1)) #transform function convert the tables into column format: easy for visualization\n",
    "  \n",
    "  # Repeating the same steps for x2\n",
    "  scores_x2 <- cut(as.matrix(x2),bins,labels = c('0','1','10','1E2','1E3','1E4','1E5','1E6','1E7','1E8','1E9','1E10'))\n",
    "  Table_x2<-transform(table(scores_x2))\n",
    "  \n",
    "  arg1 <- deparse(substitute(x1))\n",
    "  arg2 <-deparse(substitute(x2))\n",
    "  \n",
    "  data_plot <- as.data.frame(c(Table_x1$Freq,Table_x2$Freq))\n",
    "  colnames(data_plot) <- \"Freq\"\n",
    "  data_plot$Condition <- c(rep(arg1,12),rep(arg2,12))\n",
    "  data_plot$Range_bins <- rep(Table_x1$scores_x1,2)\n",
    "  data_plot$Log_Freq <- log(data_plot$Freq+1) #Log scaling the frequency values\n",
    "  \n",
    "  ## GGPLOT2\n",
    "   BarPlot <- ggplot(data_plot, aes(Range_bins, Log_Freq, fill = Condition)) + \n",
    "    geom_bar(stat=\"identity\", position = \"dodge\", width=0.4) + \n",
    "    scale_fill_brewer(palette = \"Set1\") +\n",
    "    ggtitle(label=\"Frequency plot\") +\n",
    "    xlab(\"Range\") + ylab(\"(Log)Frequency\") + labs(fill = \"Data Type\") + \n",
    "    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +   # setting the angle for the x label\n",
    "    theme(axis.text.y = element_text(angle = 45, vjust = 0.5, hjust=1)) +   # setting the angle for the y label\n",
    "    theme(plot.title = element_text(hjust = 0.5)) # centering the plot title\n",
    "  \n",
    "  print(BarPlot)\n",
    "}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a335311",
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_filled <- read.csv(\"Dummy_Quant_Table.csv\")\n",
    "not_gap_filled <- read.csv(\"Dummy_NotGapFilled_Quant_Table.csv\")\n",
    "metadata <- read_xlsx('metadata_dummy.xlsx')\n",
    "\n",
    "print(colnames(gap_filled)) \n",
    "print(colnames(not_gap_filled))\n",
    "\n",
    "#Note down the number of additional columns other than your control and sample in the dataset\n",
    "Col_range_other <- as.double(1):as.double(readline('Column_maximum_others:'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88351250",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if there are any additional columns present in the data tables and remove them. They might appear as column 'X' containing only NAs at the end of the data table.\n",
    "# For ex:\n",
    "# gap_filled <- gap_filled[,-43] \n",
    "# not_gap_filled <- not_gap_filled[,-43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2e0558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this if you want to replace zeros from the Gap_filled_Quant_Table with the minimum value of Non-gap_filled table\n",
    "if(readline('Raw Data Process - YES or NO:')=='YES'){\n",
    "    \n",
    "    GapFilled <- gap_filled[,-Col_range_other] #taking only the columns with feature intensities\n",
    "    NotGapFilled <- not_gap_filled[,-Col_range_other]\n",
    "    \n",
    "    plot<- FrequencyPlot(GapFilled,NotGapFilled)\n",
    "    \n",
    "    Arg1 = plot$data$Condition[1]\n",
    "    Arg2 = plot$data$Condition[13]\n",
    "    plotData_New <- subset(plot$data,plot$data$Freq!=0 & plot$data$Range_bins !=0) # accessing the datatable of plot and subsetting with the condition: Eliminating the Range 0 and Ranges with zero frequencies \n",
    "    First_val_temp <- aggregate(plotData_New$Freq, by=list(plotData_New$Condition), FUN=first) #getting the first appearing value of this new plot datatable\n",
    "    First_val <- plotData_New[plotData_New$Freq %in% c(First_val_temp$x[1],First_val_temp$x[2]),] # Subsetting the rows in the plotData_New that has the first appearing values\n",
    "  \n",
    "    print(paste0(\"The Range with a minimum value greater than 0 for \",Arg1,\":\", First_val$Range_bins[1]))\n",
    "    print(paste0(\"The Range with a minimum value greater than 0 for \",Arg2,\":\", First_val$Range_bins[2]))\n",
    "    \n",
    "    RawLOD <- round(min(NotGapFilled[NotGapFilled!=min(NotGapFilled)])) # getting the 2nd minimum value of non-gap filled data. (The first minimum value in the data table is usually zero)\n",
    "    GapFilled[GapFilled==0 | GapFilled<RawLOD] <- RawLOD # Replacing zeros in the gap-filled file as well as values<RawLOD with RawLOD\n",
    "    RawLOD_Table <- cbind(gap_filled[,Col_range_other],GapFilled)\n",
    "    write.csv(RawLOD_Table, file=paste0('Quant_Table_filled_with_MinValue_',RawLOD,'_NotGapFilled','.csv'),row.names =FALSE) \n",
    "    input_data <- GapFilled\n",
    "} else input_data <- gap_filled[,-Col_range_other]\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3daec2b",
   "metadata": {},
   "source": [
    "### Blank removal:\n",
    "A **metadata file** needed here to perform the blank removal on individual Ctrl-sample groups within the feature table. <br> \n",
    "\n",
    "**For example:** <br>\n",
    "In the following cell, NewFile contains only the files belonging to samples with the following conditions:\n",
    "1. that are treated with 20% MeOH\n",
    "2. strains involving only Ecoli and its control (in other words, the strains that are not Synechococcus) \n",
    "3. BG11 control media is excluded as it is used for Synechococcus. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a420e797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducing Daniel's result: (Will change this later)\n",
    "ordered_data <- input_data[,order(colnames(input_data))] #ordered the input data according to its column names\n",
    "print(colnames(ordered_data))\n",
    "\n",
    "Set1 <- ordered_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867f81af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By looking at the column names of input data, choose the desired column range for control and samples.\n",
    "Ctrl <- as.matrix(ordered_data[,as.double(readline('Column_min_Control:')):as.double(readline('Column_max_Control:'))])\n",
    "Samples <- as.matrix(ordered_data[,as.double(readline('Column_min_Samples:')):ncol(ordered_data)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077cdcfd",
   "metadata": {},
   "source": [
    "**Next 2 cells**: Don't run it now. It is for getting selective datasets within the input data using metadata information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705fb764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'NewFile' gets the file names to be extracted\n",
    "NewFile <- metadata %>% \n",
    "  filter(`ATTRIBUTE_extraction-method` == \"20MeOH\", `ATTRIBUTE_strain` != 'Synechococcus',`ATTRIBUTE_mutant` != 'BG11')\n",
    "\n",
    "# 'Set1'  uses the NewFile names and extract those files from the gap-filled data table\n",
    "Set1 <-c() \n",
    "for (i in 1:nrow(NewFile)){\n",
    "  x<- input_data[,which (colnames(input_data) == NewFile$filename[i])]\n",
    "  Set1 <- cbind(Set1,x)\n",
    "}\n",
    "colnames(Set1) <- NewFile$filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f418a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_Set1 <- Set1[,order(colnames(Set1))] #ordered the input data according to its column names\n",
    "print(colnames(ordered_Set1)) #To see all the column names of the ordered data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8566def8",
   "metadata": {},
   "source": [
    "### Finding the number of potential background or Noise features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6218ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By looking at the column names of input data, choose the desired column range for control and samples.\n",
    "Ctrl <- as.matrix(Set1[,as.double(readline('Column_min_Control:')):as.double(readline('Column_max_Control:'))])\n",
    "Samples <- as.matrix(Set1[,as.double(readline('Column_min_Samples:')):ncol(Set1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b200d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(readline('Blank Removal Process - YES or NO:')=='YES'){\n",
    "    Cutoff <- readline('Enter Cutoff value between 0.1 & 0.3:') # (i.e. 10% - 30%). \n",
    "    #When cutoff is low, more noise (or background) detected; With higher cutoff, less background detected, thus more features observed\n",
    "    Avg_ctrl <- rowMeans(Ctrl, na.rm= FALSE, dims = 1) # set na.rm = FALSE to check if there are NA values. Because when set as TRUE, NA values are changed to 0\n",
    "    Avg_samples <- rowMeans(Samples, na.rm= FALSE, dims = 1)\n",
    "    Ratio_Ctrl_Sample <- (Avg_ctrl+1)/(Avg_samples+1)\n",
    "    Bg_bin <- ifelse(Ratio_Ctrl_Sample > Cutoff, 1, 0 )  # checks if the Ratio is greater than 0, if so put 1, else 0 in Bg_bin\n",
    "\n",
    "\n",
    "# to check if there are any NA values present. It is not good to have NA values in the 4 variables as it will affect the final dataset to be created\n",
    "    temp_NA_Count <-cbind(Avg_ctrl,Avg_samples,Ratio_Ctrl_Sample,Bg_bin)\n",
    "\n",
    "    for (i in 1:ncol(temp_NA_Count)){\n",
    "      print(paste('No.of NA values in',colnames(temp_NA_Count[i]),\":\",sum(is.na(temp_NA_Count[,i])== TRUE)))\n",
    "    }\n",
    "\n",
    "    Bg_Features <- sum(Bg_bin ==1,na.rm = TRUE) # Calculates the number of background features present\n",
    "    No_of_Features <- nrow(Set1) - Bg_Features\n",
    "    print(paste(\"No.of Background or noise features:\",Bg_Features))\n",
    "    print(paste(\"No.of features after excluding noise:\",No_of_Features)) \n",
    "\n",
    "    input_data1 <- cbind(as.matrix(Set1),Bg_bin)    \n",
    "    plot_CtrlSample <- FrequencyPlot(Samples,Ctrl)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556e50a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The frequency plot shows where the features are present in higher number. \n",
    "#For ex: if until 1E2 has no or really less features, the goal is to exclude until that range and consider only values from 1E3 range. \n",
    "#Thus 1E3 is taken as Cutoff_LOD (Limit of Detection). This value will eventually become the 'new zero'\n",
    "\n",
    "#Cutoff_LOD <- as.numeric(readline(\"Enter your Cutoff LOD here:\"))   # Example: 1E2 (means 10^2). Enter the LOD value as seen in the frequency plot\n",
    "\n",
    "Cutoff_LOD <-ifelse(readline(\"Raw Data Processing done?\")==\"YES\",RawLOD,as.numeric(readline(\"Enter your Cutoff LOD here:\")))\n",
    "temp_matrix <- c()\n",
    "for (i in 1:ncol(Samples)){\n",
    "    x <- ifelse(Samples[,i] > Cutoff_LOD, Samples[,i],Cutoff_LOD)\n",
    "    temp_matrix <- cbind(temp_matrix,as.matrix(x))\n",
    "}\n",
    "colnames(temp_matrix) <- colnames(Samples)\n",
    "  \n",
    "Final_matrix <-c()\n",
    "for (i in 1:ncol(temp_matrix)){\n",
    "    x <-ifelse(input_data1[,ncol(input_data1)] ==1, Cutoff_LOD, temp_matrix[,i])\n",
    "    Final_matrix <-cbind(Final_matrix,x)\n",
    "}\n",
    "colnames(Final_matrix) <- colnames(Samples)\n",
    "write.csv(Final_matrix,file=paste0('Processed_Quant_Table_filled_with_Value_',Cutoff_LOD ,'.csv'),row.names =FALSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb727acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Final <-cbind(gap_filled[,Col_range_other],Ctrl,Final_matrix)\n",
    "Without_Cutoff<-Final[rowMeans(Final[,-Col_range_other])!= Cutoff_LOD,] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bdb6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (readline(\"Normalization: YES or NO:\") == 'YES'){  \n",
    "  sample_sum <- colSums(Without_Cutoff[,-Col_range_other], na.rm= TRUE, dims = 1)\n",
    "  Normalized_data <- c()\n",
    "  for (i in 1:ncol(Without_Cutoff[,-Col_range_other])){\n",
    "    x <- Without_Cutoff[,-Col_range_other][,i] / sample_sum[i]\n",
    "    Normalized_data <- cbind(Normalized_data, x)\n",
    "  }\n",
    "\n",
    "  colnames(Normalized_data) <- names(sample_sum)\n",
    "  Normalized_data <- cbind(Without_Cutoff[,Col_range_other],Normalized_data)\n",
    "  \n",
    "  } else return(Without_Cutoff)\n",
    "  \n",
    "print(paste('No.of NA values in Normalized data:',sum(is.na(Normalized_data)== TRUE)))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
